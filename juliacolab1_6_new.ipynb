{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "juliacolab1.6-new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia 1.6",
      "language": "julia",
      "name": "julia-1.6"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.6.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cemyr/Julia-on-Colab/blob/master/juliacolab1_6_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMGwZ7aFJL8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a0cf53ee-c2b8-48b4-df8f-a5b1cb50c056"
      },
      "source": [
        "# Installation cell\n",
        "%%capture\n",
        "%%shell\n",
        "if ! command -v julia 3>&1 > /dev/null\n",
        "then\n",
        "    wget -q 'https://julialang-s3.julialang.org/bin/linux/x64/1.6/julia-1.6.0-linux-x86_64.tar.gz' \\\n",
        "        -O /tmp/julia.tar.gz\n",
        "    tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "    rm /tmp/julia.tar.gz\n",
        "fi\n",
        "julia -e 'using Pkg; pkg\"add IJulia; precompile;\"'\n",
        "echo 'Done'"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/latex": "Unrecognized magic \\texttt{\\%\\%capture}.\n\nJulia does not use the IPython \\texttt{\\%magic} syntax.   To interact with the IJulia kernel, use \\texttt{IJulia.somefunction(...)}, for example.  Julia macros, string macros, and functions can be used to accomplish most of the other functionalities of IPython magics.\n\n",
            "text/markdown": "Unrecognized magic `%%capture`.\n\nJulia does not use the IPython `%magic` syntax.   To interact with the IJulia kernel, use `IJulia.somefunction(...)`, for example.  Julia macros, string macros, and functions can be used to accomplish most of the other functionalities of IPython magics.\n",
            "text/plain": [
              "  Unrecognized magic \u001b[36m%%capture\u001b[39m.\n",
              "\n",
              "  Julia does not use the IPython \u001b[36m%magic\u001b[39m syntax. To interact with the IJulia\n",
              "  kernel, use \u001b[36mIJulia.somefunction(...)\u001b[39m, for example. Julia macros, string\n",
              "  macros, and functions can be used to accomplish most of the other\n",
              "  functionalities of IPython magics."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVTH64SWKG6q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdMpcQduyaQc"
      },
      "source": [
        "After you run the first cell (the the cell directly above this text), go to Colab's menu bar and select **Edit** and select **Notebook settings** from the drop down. Select *Julia 1.6* as the runtime and *GPU* as the hadware accelerator.\n",
        "\n",
        "<br/>You should see something like this:\n",
        "\n",
        "> ![Colab Img](https://raw.githubusercontent.com/cemyr/Julia-on-Colab/master/julia1.6s.PNG)\n",
        "<br/>Click on SAVE\n",
        "<br/>**We are ready to get going**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIxu4TjlJnBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da72911-f647-41a2-f6d0-a07ebbbace89"
      },
      "source": [
        "VERSION"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "v\"1.6.0\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR7Ox6Ax0ypi"
      },
      "source": [
        "The main reason we are interested in running Julia on Colab is the GPU functionality. So let us benchmark the performance on the GPU.<br>**The next three cells are optional and are for people using it for the first time.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y5TUI-Ll4cY"
      },
      "source": [
        "### Optional GPU Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHKANz2J0GDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b28ecd9-cf30-4e22-8075-e562d6857cdf"
      },
      "source": [
        "using Pkg\n",
        "Pkg.add([\"BenchmarkTools\", \"CUDA\"])\n",
        "using BenchmarkTools, CUDA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Memoize ──────────── v0.4.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BenchmarkTools ───── v0.7.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OrderedCollections ─ v1.4.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MacroTools ───────── v0.5.6\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChainRulesCore ───── v0.9.37\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DataStructures ───── v0.18.9\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Adapt ────────────── v3.2.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Requires ─────────── v1.1.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m AbstractFFTs ─────── v1.0.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LLVM ─────────────── v3.6.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m TimerOutputs ─────── v0.5.8\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Scratch ──────────── v1.0.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GPUArrays ────────── v6.2.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ExprTools ────────── v0.1.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Reexport ─────────── v1.0.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BFloat16s ────────── v0.1.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CEnum ────────────── v0.4.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GPUCompiler ──────── v0.10.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Compat ───────────── v3.27.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NNlib ────────────── v0.7.18\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CUDA ─────────────── v2.6.3\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Project.toml`\n",
            " \u001b[90m [6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v0.7.0\u001b[39m\n",
            " \u001b[90m [052768ef] \u001b[39m\u001b[92m+ CUDA v2.6.3\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Manifest.toml`\n",
            " \u001b[90m [621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v1.0.1\u001b[39m\n",
            " \u001b[90m [79e6a3ab] \u001b[39m\u001b[92m+ Adapt v3.2.0\u001b[39m\n",
            " \u001b[90m [ab4f0b2a] \u001b[39m\u001b[92m+ BFloat16s v0.1.0\u001b[39m\n",
            " \u001b[90m [6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v0.7.0\u001b[39m\n",
            " \u001b[90m [fa961155] \u001b[39m\u001b[92m+ CEnum v0.4.1\u001b[39m\n",
            " \u001b[90m [052768ef] \u001b[39m\u001b[92m+ CUDA v2.6.3\u001b[39m\n",
            " \u001b[90m [d360d2e6] \u001b[39m\u001b[92m+ ChainRulesCore v0.9.37\u001b[39m\n",
            " \u001b[90m [34da2185] \u001b[39m\u001b[92m+ Compat v3.27.0\u001b[39m\n",
            " \u001b[90m [864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.18.9\u001b[39m\n",
            " \u001b[90m [e2ba6199] \u001b[39m\u001b[92m+ ExprTools v0.1.3\u001b[39m\n",
            " \u001b[90m [0c68f7d7] \u001b[39m\u001b[92m+ GPUArrays v6.2.1\u001b[39m\n",
            " \u001b[90m [61eb1bfa] \u001b[39m\u001b[92m+ GPUCompiler v0.10.0\u001b[39m\n",
            " \u001b[90m [929cbde3] \u001b[39m\u001b[92m+ LLVM v3.6.0\u001b[39m\n",
            " \u001b[90m [1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.6\u001b[39m\n",
            " \u001b[90m [c03570c3] \u001b[39m\u001b[92m+ Memoize v0.4.4\u001b[39m\n",
            " \u001b[90m [872c559c] \u001b[39m\u001b[92m+ NNlib v0.7.18\u001b[39m\n",
            " \u001b[90m [bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.4.0\u001b[39m\n",
            " \u001b[90m [189a3867] \u001b[39m\u001b[92m+ Reexport v1.0.0\u001b[39m\n",
            " \u001b[90m [ae029012] \u001b[39m\u001b[92m+ Requires v1.1.3\u001b[39m\n",
            " \u001b[90m [6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.0.3\u001b[39m\n",
            " \u001b[90m [a759f4b9] \u001b[39m\u001b[92m+ TimerOutputs v0.5.8\u001b[39m\n",
            " \u001b[90m [8bb1440f] \u001b[39m\u001b[92m+ DelimitedFiles\u001b[39m\n",
            " \u001b[90m [8ba89e20] \u001b[39m\u001b[92m+ Distributed\u001b[39m\n",
            " \u001b[90m [4af54fe1] \u001b[39m\u001b[92m+ LazyArtifacts\u001b[39m\n",
            " \u001b[90m [37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra\u001b[39m\n",
            " \u001b[90m [1a1011a3] \u001b[39m\u001b[92m+ SharedArrays\u001b[39m\n",
            " \u001b[90m [2f01184e] \u001b[39m\u001b[92m+ SparseArrays\u001b[39m\n",
            " \u001b[90m [10745b16] \u001b[39m\u001b[92m+ Statistics\u001b[39m\n",
            " \u001b[90m [e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll\u001b[39m\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mCEnum\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mRequires\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mAdapt\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mCompilerSupportLibraries_jll\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mCompat\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39mBenchmarkTools\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mExprTools\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mMacroTools\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mOrderedCollections\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mAbstractFFTs\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mReexport\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mBFloat16s\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mTimerOutputs\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mScratch\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mMemoize\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mChainRulesCore\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mDataStructures\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mGPUArrays\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mLLVM\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mNNlib\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mGPUCompiler\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39mCUDA\n",
            "22 dependencies successfully precompiled in 50 seconds (14 already precompiled)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7Mbcm00lnxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a938d3e0-f85e-43ad-eb38-0ed168eb7026"
      },
      "source": [
        "mcpu = rand(2^10, 2^10)\n",
        "@benchmark mcpu*mcpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: \n",
              "  memory estimate:  8.00 MiB\n",
              "  allocs estimate:  2\n",
              "  --------------\n",
              "  minimum time:     54.031 ms (0.00% GC)\n",
              "  median time:      57.115 ms (0.00% GC)\n",
              "  mean time:        57.773 ms (0.71% GC)\n",
              "  maximum time:     67.917 ms (0.00% GC)\n",
              "  --------------\n",
              "  samples:          87\n",
              "  evals/sample:     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMHRbF5J-vmW",
        "outputId": "6c1c2f21-eb46-4ea9-9d9a-c914e3af5969"
      },
      "source": [
        "println(\"The CuArrray operation should take around 0.5 ms(excluding CUDA downloading time which is a one time process), and should be much faster. If so, the GPU is working.\")\n",
        "mgpu = cu(mcpu)\n",
        "@benchmark CUDA.@sync mgpu*mgpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The CuArrray operation should take around 0.5 ms(excluding CUDA downloading time which is a one time process), and should be much faster. If so, the GPU is working.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BenchmarkTools.Trial: \n",
              "  memory estimate:  896 bytes\n",
              "  allocs estimate:  37\n",
              "  --------------\n",
              "  minimum time:     490.967 μs (0.00% GC)\n",
              "  median time:      614.534 μs (0.00% GC)\n",
              "  mean time:        625.298 μs (0.13% GC)\n",
              "  maximum time:     10.985 ms (0.00% GC)\n",
              "  --------------\n",
              "  samples:          7844\n",
              "  evals/sample:     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKaeZEIpATm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33358be6-705d-41b6-b145-7e9b6d82125e"
      },
      "source": [
        "has_cuda_gpu()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "true"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4DdVEmSd_Ve",
        "outputId": "f71157ec-ada9-4333-ef2f-bf86af40e981"
      },
      "source": [
        "CUDA.device()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CuDevice(0): Tesla T4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}